{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9a3a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob as glob\n",
    "import dill\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279c4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_fn(filename):\n",
    "    date_string = filename[-14:-4]\n",
    "    datetime_object = datetime.datetime.strptime(date_string, \"%Y-%m-%d\")\n",
    "    return datetime_object\n",
    "\n",
    "x_scaler_minmax = dill.load(open(\"../scalers/x_SPCAM5_minmax_scaler.dill\", 'rb'))\n",
    "y_scaler_minmax = dill.load(open(f\"../scalers/y_SPCAM5_minmax_scaler.dill\", 'rb'))\n",
    "x_scaler_minmax.min = x_scaler_minmax.min * 0\n",
    "x_scaler_minmax.max = np.abs(x_scaler_minmax.max)\n",
    "y_scaler_minmax.min = y_scaler_minmax.min[:26] * 0\n",
    "y_scaler_minmax.max = np.abs(y_scaler_minmax.max[:26])\n",
    "\n",
    "x_data = sorted(glob.glob(f\"../../SPCAM5/inputs_*\"), key=sort_fn)\n",
    "y_data = sorted(glob.glob(f\"../../SPCAM5/outputs_*\"), key=sort_fn)\n",
    "\n",
    "split_n = int(365*0.8)\n",
    "x_train = x_data[:split_n]\n",
    "y_train = y_data[:split_n]\n",
    "x_valid = x_data[split_n:365]\n",
    "y_valid = y_data[split_n:365]\n",
    "x_test = x_data[365:]\n",
    "y_test = y_data[365:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6bf9e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 84/292 [00:10<00:24,  8.52it/s]"
     ]
    }
   ],
   "source": [
    "x_train_df = pd.DataFrame()\n",
    "for x_paths in tqdm(x_train, total=len(x_train)):\n",
    "    x = np.load(x_paths)\n",
    "    loadDf = pd.DataFrame([x.mean(axis=0), x.min(axis=0), x.max(axis=0)])\n",
    "    x_train_df = pd.concat([x_train_df, loadDf], axis=0)\n",
    "x_train_df = x_train_df.reset_index(drop=True)\n",
    "\n",
    "y_train_df = pd.DataFrame()\n",
    "for y_paths in tqdm(y_train, total=len(y_train)):\n",
    "    y = np.load(y_paths)[:, :26]\n",
    "    loadDf = pd.DataFrame([y.mean(axis=0), y.min(axis=0), y.max(axis=0)])\n",
    "    y_train_df = pd.concat([y_train_df, loadDf], axis=0)\n",
    "y_train_df = y_train_df.reset_index(drop=True)\n",
    "\n",
    "x_valid_df = pd.DataFrame()\n",
    "for x_paths in tqdm(x_valid, total=len(x_valid)):\n",
    "    x = np.load(x_paths)\n",
    "    x = x_scaler_minmax.transform(x)\n",
    "    loadDf = pd.DataFrame([x.mean(axis=0), x.min(axis=0), x.max(axis=0)])\n",
    "    x_valid_df = pd.concat([x_valid_df, loadDf], axis=0)\n",
    "x_valid_df = x_valid_df.reset_index(drop=True)\n",
    "\n",
    "y_valid_df = pd.DataFrame()\n",
    "for y_paths in tqdm(y_valid, total=len(y_valid)):\n",
    "    y = np.load(y_paths)[:, :26]\n",
    "    loadDf = pd.DataFrame([y.mean(axis=0), y.min(axis=0), y.max(axis=0)])\n",
    "    y_valid_df = pd.concat([y_valid_df, loadDf], axis=0)\n",
    "y_valid_df = y_valid_df.reset_index(drop=True)\n",
    "\n",
    "x_test_df = pd.DataFrame()\n",
    "for x_paths in tqdm(x_test, total=len(x_test)):\n",
    "    x = np.load(x_paths)\n",
    "    loadDf = pd.DataFrame([x.mean(axis=0), x.min(axis=0), x.max(axis=0)])\n",
    "    x_test_df = pd.concat([x_test_df, loadDf], axis=0)\n",
    "x_test_df = x_test_df.reset_index(drop=True)\n",
    "\n",
    "y_test_df = pd.DataFrame()\n",
    "for y_paths in tqdm(y_test, total=len(y_test)):\n",
    "    y = np.load(y_paths)[:, :26]\n",
    "    loadDf = pd.DataFrame([y.mean(axis=0), y.min(axis=0), y.max(axis=0)])\n",
    "    y_test_df = pd.concat([y_test_df, loadDf], axis=0)\n",
    "y_test_df = y_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6422eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9\n",
    "for v in range(108 // n):\n",
    "    sns.violinplot(data=x_train_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/x_train_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "    sns.violinplot(data=x_valid_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/x_valid_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "    sns.violinplot(data=x_test_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/x_test_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "\n",
    "n = 4\n",
    "for v in range(26//n+1):\n",
    "    sns.violinplot(data=y_train_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/y_train_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "    sns.violinplot(data=y_valid_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/y_valid_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "    sns.violinplot(data=y_test_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/y_test_{v*n}_violion.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73395003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the scaled min, mean, max of each variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 292/292 [04:24<00:00,  1.11it/s]\n",
      "  0%|          | 0/292 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (331776,108) (112,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m y_paths \u001b[39min\u001b[39;00m tqdm(x_train, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(x_train)):\n\u001b[1;32m     11\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(y_paths)\n\u001b[0;32m---> 12\u001b[0m     y \u001b[39m=\u001b[39m y_scaler_minmax\u001b[39m.\u001b[39;49mtransform(y)\n\u001b[1;32m     13\u001b[0m     loadDf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([y\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), y\u001b[39m.\u001b[39mmin(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), y\u001b[39m.\u001b[39mmax(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)])\n\u001b[1;32m     14\u001b[0m     y_train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([y_train_df, loadDf], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/data/kai/climate_neural_processes/notebooks/lib/utils.py:24\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m     23\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m---> 24\u001b[0m     out \u001b[39m=\u001b[39m (data \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin) \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin)\n\u001b[1;32m     25\u001b[0m     out[np\u001b[39m.\u001b[39misinf(out) \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39misnan(out) \u001b[39m|\u001b[39m (out \u001b[39m>\u001b[39m \u001b[39m1e8\u001b[39m)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (331776,108) (112,) "
     ]
    }
   ],
   "source": [
    "x_train_df = pd.DataFrame()\n",
    "for x_paths in tqdm(x_train, total=len(x_train)):\n",
    "    x = np.load(x_paths)\n",
    "    x = x_scaler_minmax.transform(x)\n",
    "    loadDf = pd.DataFrame([x.mean(axis=0), x.min(axis=0), x.max(axis=0)])\n",
    "    x_train_df = pd.concat([x_train_df, loadDf], axis=0)\n",
    "x_train_df = x_train_df.reset_index(drop=True)\n",
    "\n",
    "y_train_df = pd.DataFrame()\n",
    "for y_paths in tqdm(x_train, total=len(x_train)):\n",
    "    y = np.load(y_paths)[:, :26]\n",
    "    y = y_scaler_minmax.transform(y)\n",
    "    loadDf = pd.DataFrame([y.mean(axis=0), y.min(axis=0), y.max(axis=0)])\n",
    "    y_train_df = pd.concat([y_train_df, loadDf], axis=0)\n",
    "y_train_df = y_train_df.reset_index(drop=True)\n",
    "\n",
    "x_valid_df = pd.DataFrame()\n",
    "for x_paths in tqdm(x_valid, total=len(x_valid)):\n",
    "    x = np.load(x_paths)\n",
    "    x = x_scaler_minmax.transform(x)\n",
    "    loadDf = pd.DataFrame([x.mean(axis=0), x.min(axis=0), x.max(axis=0)])\n",
    "    x_valid_df = pd.concat([x_valid_df, loadDf], axis=0)\n",
    "x_valid_df = x_valid_df.reset_index(drop=True)\n",
    "\n",
    "y_valid_df = pd.DataFrame()\n",
    "for y_paths in tqdm(y_valid, total=len(y_valid)):\n",
    "    y = np.load(y_paths)[:, :26]\n",
    "    y = y_scaler_minmax.transform(y)\n",
    "    loadDf = pd.DataFrame([y.mean(axis=0), y.min(axis=0), y.max(axis=0)])\n",
    "    y_valid_df = pd.concat([y_valid_df, loadDf], axis=0)\n",
    "y_valid_df = y_valid_df.reset_index(drop=True)\n",
    "\n",
    "x_test_df = pd.DataFrame()\n",
    "for x_paths in tqdm(x_test, total=len(x_test)):\n",
    "    x = np.load(x_paths)\n",
    "    x = x_scaler_minmax.transform(x)\n",
    "    loadDf = pd.DataFrame([x.mean(axis=0), x.min(axis=0), x.max(axis=0)])\n",
    "    x_test_df = pd.concat([x_test_df, loadDf], axis=0)\n",
    "x_test_df = x_test_df.reset_index(drop=True)\n",
    "\n",
    "y_test_df = pd.DataFrame()\n",
    "for y_paths in tqdm(y_test, total=len(y_test)):\n",
    "    y = np.load(y_paths)[:, :26]\n",
    "    y = y_scaler_minmax.transform(y)\n",
    "    loadDf = pd.DataFrame([y.mean(axis=0), y.min(axis=0), y.max(axis=0)])\n",
    "    y_test_df = pd.concat([y_test_df, loadDf], axis=0)\n",
    "y_test_df = y_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f30771",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9\n",
    "for v in range(108 // n):\n",
    "    sns.violinplot(data=x_train_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/x_train_scaled_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "    sns.violinplot(data=x_valid_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/x_valid_scaled_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "    sns.violinplot(data=x_test_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/x_test_scaled_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "\n",
    "n = 4\n",
    "for v in range(26//n+1):\n",
    "    sns.violinplot(data=y_train_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/y_train_scaled_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "    sns.violinplot(data=y_valid_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/y_valid_scaled_{v*n}_violion.png\")\n",
    "    plt.close()\n",
    "    sns.violinplot(data=y_test_df.iloc[:, v*n:(v+1)*n])\n",
    "    plt.savefig(f\"plots/y_test_scaled_{v*n}_violion.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69adaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
