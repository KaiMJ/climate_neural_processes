{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "sys.path.append('../src/')\n",
    "import sys\n",
    "# sys.path.append('..')\n",
    "from lib.dataset import *\n",
    "from lib.loss import *\n",
    "from lib.utils import *\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from SFNP.model import Model as SFNP_Model\n",
    "from transformer.model import Model as Transformer_Model\n",
    "from MFNP.model import Model as MFNP_Model\n",
    "from SF_Attn_process.model import Model as SF_Attn_process_Model\n",
    "import os, yaml, glob, dill\n",
    "from tqdm import tqdm\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self, dirpath, Model):\n",
    "        self.dirpath = dirpath\n",
    "        if Model == Transformer_Model:\n",
    "            self.forward = True\n",
    "        else:\n",
    "            self.forward = False\n",
    "        if Model == MFNP_Model:\n",
    "            self.multi = True\n",
    "        else:\n",
    "            self.multi = False\n",
    "        self.config = yaml.safe_load(open(f\"{dirpath}/saved_config.yaml\"))\n",
    "        self.init_dataloader()\n",
    "        self.Model = Model\n",
    "        self.init_model()\n",
    "\n",
    "    def init_model(self):\n",
    "        self.device = torch.device('cuda')\n",
    "        model_dict = torch.load(f\"{self.dirpath}/best.pt\", map_location=torch.device('cuda'))\n",
    "        model = self.Model(model_dict['config']['model']).to(self.device)\n",
    "\n",
    "        model.load_state_dict(model_dict['model'])\n",
    "        model.eval()\n",
    "        self.model = model\n",
    "\n",
    "    def init_dataloader(self):\n",
    "        l2_x_data = sorted(glob.glob(f\"{self.config['data_dir']}/SPCAM5/inputs_*\"), key=sort_fn)\n",
    "        l2_y_data = sorted(glob.glob(f\"{self.config['data_dir']}/SPCAM5/outputs_*\"), key=sort_fn)\n",
    "        l1_x_data = sorted(glob.glob(f\"{self.config['data_dir']}/CAM5/inputs_*\"), key=sort_fn)\n",
    "        l1_y_data = sorted(glob.glob(f\"{self.config['data_dir']}/CAM5/outputs_*\"), key=sort_fn)\n",
    "\n",
    "        n = int(365*0.8)\n",
    "        self.l2_x_train = l2_x_data[:n]\n",
    "        self.l2_y_train = l2_y_data[:n]\n",
    "        self.l2_x_valid = l2_x_data[n:365]\n",
    "        self.l2_y_valid = l2_y_data[n:365]\n",
    "        self.l2_x_test = l2_x_data[365:]\n",
    "        self.l2_y_test = l2_y_data[365:]\n",
    "        self.l1_x_train = l1_x_data[:n]\n",
    "        self.l1_y_train = l1_y_data[:n]\n",
    "        self.l1_x_valid = l1_x_data[n:365]\n",
    "        self.l1_y_valid = l1_y_data[n:365]\n",
    "        self.l1_x_test = l1_x_data[365:]\n",
    "        self.l1_y_test = l1_y_data[365:]\n",
    "        l1_x_scaler_minmax = dill.load(open(f\"../../scalers/x_CAM5_minmax_scaler.dill\", 'rb'))\n",
    "        l1_y_scaler_minmax = dill.load(open(f\"../../scalers/y_CAM5_minmax_scaler.dill\", 'rb'))\n",
    "\n",
    "        l2_x_scaler_minmax = dill.load(open(f\"../../scalers/x_SPCAM5_minmax_scaler.dill\", 'rb'))\n",
    "        l2_y_scaler_minmax = dill.load(open(f\"../../scalers/y_SPCAM5_minmax_scaler.dill\", 'rb'))\n",
    "\n",
    "        # Change to first 26 variables\n",
    "        l2_y_scaler_minmax.min = l2_y_scaler_minmax.min[:26]\n",
    "        l2_y_scaler_minmax.max = l2_y_scaler_minmax.max[:26]\n",
    "        l1_y_scaler_minmax.min = l1_y_scaler_minmax.min[:26]\n",
    "        l1_y_scaler_minmax.max = l1_y_scaler_minmax.max[:26]\n",
    "\n",
    "        if not self.multi:\n",
    "            trainset = l2Dataset(self.l2_x_train, self.l2_y_train, x_scaler=l2_x_scaler_minmax, y_scaler=l2_y_scaler_minmax, variables=26)\n",
    "            self.trainloader = DataLoader(trainset, batch_size=self.config['batch_size'], shuffle=True, drop_last=False, \\\n",
    "                                            num_workers=4, pin_memory=True)\n",
    "            validset = l2Dataset(self.l2_x_valid, self.l2_y_valid, x_scaler=l2_x_scaler_minmax, y_scaler=l2_y_scaler_minmax, variables=26)\n",
    "            self.validloader = DataLoader(validset, batch_size=self.config['batch_size'], shuffle=False, drop_last=False, \\\n",
    "                                            num_workers=4, pin_memory=True)\n",
    "            testset = l2Dataset(self.l2_x_test, self.l2_y_test, x_scaler=l2_x_scaler_minmax, y_scaler=l2_y_scaler_minmax, variables=26)\n",
    "            self.testloader = DataLoader(testset, batch_size=self.config['batch_size'], shuffle=False, drop_last=False, \\\n",
    "                                        num_workers=4, pin_memory=True)\n",
    "        else:\n",
    "            trainset = MutliDataset(self.l1_x_train, self.l1_y_train, self.l2_x_train, self.l2_y_train,\n",
    "                                            l1_x_scaler=l1_x_scaler_minmax, l1_y_scaler=l1_y_scaler_minmax,\n",
    "                                            l2_x_scaler=l2_x_scaler_minmax, l2_y_scaler=l2_y_scaler_minmax, nested=self.config['nested'], variables=[26, 26])\n",
    "            self.trainloader = DataLoader(trainset, self.config['batch_size'], shuffle=True, drop_last=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "            validset = MutliDataset(self.l1_x_valid, self.l1_y_valid, self.l2_x_valid, self.l2_y_valid,\n",
    "                                    l1_x_scaler=l1_x_scaler_minmax, l1_y_scaler=l1_y_scaler_minmax,\n",
    "                                    l2_x_scaler=l2_x_scaler_minmax, l2_y_scaler=l2_y_scaler_minmax, nested=self.config['nested'], variables=[26, 26])\n",
    "            self.validloader = DataLoader(validset, self.config['batch_size'], shuffle=False, drop_last=False, num_workers=0, pin_memory=True)\n",
    "            testset = MutliDataset(self.l1_x_test, self.l1_y_test, self.l2_x_test, self.l2_y_test, l1_x_scaler=l1_x_scaler_minmax, l1_y_scaler=l1_y_scaler_minmax, nested=self.config['nested'], variables=[26, 26])\n",
    "            self.testloader = DataLoader(testset, self.config['batch_size'], shuffle=False, drop_last=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "        self.l2_y_scaler_minmax = l2_y_scaler_minmax\n",
    "\n",
    "    def get_metrics(self, loader):\n",
    "        self.get_R_stats(loader)\n",
    "        self.r = self.ssxym / np.sqrt(self.ssxm * self.ssym)\n",
    "        return self.r\n",
    "\n",
    "    def get_R_stats(self, loader):\n",
    "        self._get_stats(loader)\n",
    "        self.ssxm = 0\n",
    "        self.ssxym = 0\n",
    "        self.ssym = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(loader, total=len(loader))):\n",
    "                if self.multi:\n",
    "                    l1_x, l1_y, l2_x, l2_y = data\n",
    "                    l1_x = l1_x.reshape(-1, 1, l1_x.shape[-1]).to(device)\n",
    "                    l1_y = l1_y.reshape(-1, 1, l1_y.shape[-1]).to(device)\n",
    "                else:\n",
    "                    l2_x, l2_y = data\n",
    "\n",
    "                l2_x = l2_x.reshape(-1, 1, l2_x.shape[-1]).to(device)\n",
    "                l2_y = l2_y.reshape(-1, 1, l2_y.shape[-1]).to(device)\n",
    "                if self.forward:\n",
    "                    l2_output_mu = self.model(l2_x)\n",
    "                    l2_truth = l2_y\n",
    "                elif self.multi:\n",
    "                    l1_output_mu, l1_output_cov, l2_output_mu, l2_output_cov, l1_y_truth,\\\n",
    "                        l2_truth, l1_z_mu_all, l1_z_cov_all, l1_z_mu_c, l1_z_cov_c, \\\n",
    "                        l2_z_mu_all, l2_z_cov_all, l2_z_mu_c, l2_z_cov_c = self.model(l1_x, l1_y, l2_x, l2_y)\n",
    "                else:\n",
    "                    l2_output_mu, l2_output_cov, l2_truth, l2_z_mu_all, \\\n",
    "                            l2_z_cov_all, l2_z_mu_c, l2_z_cov_c = self.model(l2_x, l2_y)\n",
    "                \n",
    "                non_y_pred = self.l2_y_scaler_minmax.inverse_transform(l2_output_mu.squeeze().cpu().numpy())\n",
    "                non_y = self.l2_y_scaler_minmax.inverse_transform(l2_truth.squeeze().cpu().numpy())\n",
    "\n",
    "                self.ssxm += ((non_y - self.y_mean)**2).sum(0)\n",
    "                self.ssym += ((non_y_pred - self.y_pred_mean)**2).sum(0)\n",
    "                self.ssxym += ((non_y - self.y_mean) * (non_y_pred - self.y_pred_mean)).sum(0)\n",
    "            # Get average\n",
    "            self.ssxm /= self.n_total\n",
    "            self.ssym /= self.n_total\n",
    "            self.ssxym /= self.n_total\n",
    "\n",
    "    def _get_stats(self, loader):\n",
    "        self.n_total = 0\n",
    "        self.x_total = 0\n",
    "        self.y_total = 0\n",
    "        self.xy_total = 0\n",
    "        self.x2_total = 0\n",
    "        self.y2_total = 0\n",
    "        self.y_mean = 0\n",
    "        self.y_pred_mean = 0\n",
    "        self.nmae = 0\n",
    "        self.non_mae = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(loader, total=len(loader))):\n",
    "                if self.multi:\n",
    "                    l1_x, l1_y, l2_x, l2_y = data\n",
    "                    l1_x = l1_x.reshape(-1, 1, l1_x.shape[-1]).to(device)\n",
    "                    l1_y = l1_y.reshape(-1, 1, l1_y.shape[-1]).to(device)\n",
    "                else:\n",
    "                    l2_x, l2_y = data\n",
    "\n",
    "                l2_x = l2_x.reshape(-1, 1, l2_x.shape[-1]).to(device)\n",
    "                l2_y = l2_y.reshape(-1, 1, l2_y.shape[-1]).to(device)\n",
    "                if self.forward:\n",
    "                    l2_output_mu = self.model(l2_x)\n",
    "                    l2_truth = l2_y\n",
    "                elif self.multi:\n",
    "                    l1_output_mu, l1_output_cov, l2_output_mu, l2_output_cov, l1_y_truth,\\\n",
    "                        l2_truth, l1_z_mu_all, l1_z_cov_all, l1_z_mu_c, l1_z_cov_c, \\\n",
    "                        l2_z_mu_all, l2_z_cov_all, l2_z_mu_c, l2_z_cov_c = self.model(l1_x, l1_y, l2_x, l2_y)\n",
    "                else:\n",
    "                    l2_output_mu, l2_output_cov, l2_truth, l2_z_mu_all, \\\n",
    "                            l2_z_cov_all, l2_z_mu_c, l2_z_cov_c = self.model(l2_x, l2_y)\n",
    "\n",
    "                non_y_pred = self.l2_y_scaler_minmax.inverse_transform(l2_output_mu.squeeze().cpu().numpy())\n",
    "                non_y = self.l2_y_scaler_minmax.inverse_transform(l2_truth.squeeze().cpu().numpy())\n",
    "                non_mae = mae_metric(non_y_pred, non_y, mean=False)\n",
    "\n",
    "                self.y_mean += non_y.sum(axis=0)\n",
    "                self.y_pred_mean += non_y_pred.sum(axis=0)\n",
    "                self.non_mae += non_mae.sum(axis=0)\n",
    "                self.n_total += non_y.shape[0]\n",
    "                self.x_total += non_y.sum(axis=0)\n",
    "                self.y_total += non_y_pred.sum(axis=0)\n",
    "                self.x2_total += (non_y ** 2).sum(axis=0)\n",
    "                self.y2_total += (non_y_pred ** 2).sum(axis=0)\n",
    "                self.xy_total += (non_y_pred * non_y).sum(axis=0)\n",
    "\n",
    "        self.y_mean /= self.n_total\n",
    "        self.y_pred_mean /= self.n_total\n",
    "        self.nmae /= self.n_total\n",
    "        self.non_mae /= self.n_total\n",
    "        self.nmae = np.abs(np.sqrt(self.non_mae / self.n_total) / np.abs(self.y_mean))\n",
    "\n",
    "\n",
    "    def get_loss_plot(self):\n",
    "        \n",
    "        return self.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFNP_path = \"logs/SFNP_train_seed0_lr0.000168_bs_1_Tue Feb 28 01:09:51 2023\"\n",
    "Transformer_path = \"logs/transformer_tune_seed0_lr7.7e-05_bs_1_Tue Feb 28 09:39:20 2023\"\n",
    "MFNP_path = \"logs/mfnp_tune_seed0_lr9.9e-05_bs_1_Tue Feb 28 10:58:15 2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model init\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(cwd, \"../src/SFNP\"))\n",
    "evaluator_sfnp = Evaluator(SFNP_path, SFNP_Model)\n",
    "os.chdir(os.path.join(cwd, \"../src/transformer\"))\n",
    "evaluator_transformer = Evaluator(Transformer_path, Transformer_Model)\n",
    "os.chdir(os.path.join(cwd, \"../src/MFNP\"))\n",
    "evaluator_mfnp = Evaluator(MFNP_path, MFNP_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(title):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].bar(np.arange(26), evaluator_sfnp.non_mae, label=\"SFNP\", alpha=0.5)\n",
    "    axs[0].bar(np.arange(26), evaluator_transformer.non_mae, label=\"Transformer\", alpha=0.5)\n",
    "    axs[0].bar(np.arange(26), evaluator_mfnp.non_mae, label=\"MFNP\", alpha=0.5)\n",
    "    axs[0].set_title(\"Mean Absolute Error\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].bar(np.arange(26), evaluator_sfnp.nmae, label=\"SFNP\", alpha=0.5)\n",
    "    axs[1].bar(np.arange(26), evaluator_transformer.nmae, label=\"Transformer\", alpha=0.5)\n",
    "    axs[1].bar(np.arange(26), evaluator_mfnp.nmae, label=\"MFNP\", alpha=0.5)\n",
    "    axs[1].set_title(\"Normalized Mean Absolute Error\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    axs[2].bar(np.arange(26), evaluator_sfnp.r, label=\"SFNP\", alpha=0.5)\n",
    "    axs[2].bar(np.arange(26), evaluator_transformer.r, label=\"Transformer\", alpha=0.5)\n",
    "    axs[2].bar(np.arange(26), evaluator_mfnp.r, label=\"MFNP\", alpha=0.5)\n",
    "    axs[2].set_title(\"Correlation R\")\n",
    "    axs[2].legend()\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/292 [00:07<18:34,  3.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# evaluator_sfnp.get_metrics(evaluator_sfnp.trainloader)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# evaluator_transformer.get_metrics(evaluator_transformer.trainloader)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m evaluator_mfnp\u001b[39m.\u001b[39;49mget_metrics(evaluator_mfnp\u001b[39m.\u001b[39;49mtrainloader)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plot_bar(\u001b[39m\"\u001b[39m\u001b[39mTrain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# R_sfnp_valid = evaluator_sfnp.get_metrics(evaluator_sfnp.validloader)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# R_transformer_valid = evaluator_transformer.get_metrics(evaluator_transformer.validloader)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# evaluator_mfnp.get_metrics(evaluator_mfnp.validloader)\u001b[39;00m\n",
      "\u001b[1;32m/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb Cell 6\u001b[0m in \u001b[0;36mEvaluator.get_metrics\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_metrics\u001b[39m(\u001b[39mself\u001b[39m, loader):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_R_stats(loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssxym \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssxm \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssym)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr\n",
      "\u001b[1;32m/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb Cell 6\u001b[0m in \u001b[0;36mEvaluator.get_R_stats\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_R_stats\u001b[39m(\u001b[39mself\u001b[39m, loader):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_stats(loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssxm \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssxym \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;32m/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb Cell 6\u001b[0m in \u001b[0;36mEvaluator._get_stats\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnon_mae \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(loader, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(loader))):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmulti:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/mkim/Nserver/climate_processes/notebooks/eval.ipynb#W4sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m             l1_x, l1_y, l2_x, l2_y \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Nserver/climate_processes/notebooks/../src/lib/dataset.py:65\u001b[0m, in \u001b[0;36mMutliDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     62\u001b[0m     l2_y \u001b[39m=\u001b[39m l2_y[:, :\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[\u001b[39m1\u001b[39m]]\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1_x_scaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     l1_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_x_scaler\u001b[39m.\u001b[39;49mtransform(l1_x)\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1_y_scaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     l1_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1_y_scaler\u001b[39m.\u001b[39mtransform(l1_y)\n",
      "File \u001b[0;32m~/Nserver/climate_processes/notebooks/../src/lib/utils.py:45\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     43\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mRuntimeWarning\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m out \u001b[39m=\u001b[39m (data \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin) \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin)\n\u001b[0;32m---> 45\u001b[0m out[np\u001b[39m.\u001b[39;49misinf(out) \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39misnan(out) \u001b[39m|\u001b[39m (out \u001b[39m>\u001b[39m \u001b[39m1e8\u001b[39m)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluator_sfnp.get_metrics(evaluator_sfnp.trainloader)\n",
    "evaluator_transformer.get_metrics(evaluator_transformer.trainloader)\n",
    "evaluator_mfnp.get_metrics(evaluator_mfnp.trainloader)\n",
    "\n",
    "plot_bar(\"Train\")\n",
    "\n",
    "R_sfnp_valid = evaluator_sfnp.get_metrics(evaluator_sfnp.validloader)\n",
    "R_transformer_valid = evaluator_transformer.get_metrics(evaluator_transformer.validloader)\n",
    "evaluator_mfnp.get_metrics(evaluator_mfnp.validloader)\n",
    "plot_bar(\"valid\")\n",
    "\n",
    "R_sfnp_test = evaluator_sfnp.get_metrics(evaluator_sfnp.testloader)\n",
    "R_transformer_test = evaluator_transformer.get_metrics(evaluator_transformer.testloader)\n",
    "evaluator_mfnp.get_metrics(evaluator_mfnp.testloader)\n",
    "plot_bar(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5529f52d43dbfc9fee230ba5e7607dce6de3247df14ba2bd24aec3ce54489fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
